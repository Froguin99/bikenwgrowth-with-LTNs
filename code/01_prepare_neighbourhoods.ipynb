{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pre-process neighbourhood data\n",
    "## Project: Growing Urban Bicycle Networks with an LTN twist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the outputs of the ltnDetection (https://github.com/Froguin99/LTN-Detection) and prepares them for later use within the bike network growth project\n",
    "\n",
    "Contact: Chris Larkin (c.larkin@ncl.ac.uk) \n",
    "\n",
    "Created: 2025-03-26  \n",
    "Last modified: 2025-03-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PATH.\n",
      "\n",
      "Setup finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "\n",
    "%load_ext watermark\n",
    "#%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded functions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in neighbourhoods and extract \"ltns\" from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- store ltns on a public location to avoid manually having to find the data. Currently hosting Tyne & Wear on Github as geopackages, not very flexible\n",
    "- set up fuzzy matching of place names to growbike's use of placenames (e.g. Newcastle Upon Tyne --> newcastle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LTNs and Normal Neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old manual way of getting locations\n",
    "# placename = \"Gateshead\"\n",
    "# neighbourhoods = gpd.read_file(r'C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\ltnDetection\\LTN-Detection\\data\\scored_neighbourhoods\\scored_neighbourhoods_{}.gpkg'.format(placename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../../bikenwgrowth_external/data/gateshead\\scored_neighbourhoods_gateshead.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/newcastle\\scored_neighbourhoods_newcastle.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/south_tyneside\\scored_neighbourhoods_south_tyneside.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/sunderland\\scored_neighbourhoods_sunderland.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/north_tyneside\\scored_neighbourhoods_north_tyneside.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/gateshead\\neighbourhoods_gateshead.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/newcastle\\neighbourhoods_newcastle.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/south_tyneside\\neighbourhoods_south_tyneside.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/sunderland\\neighbourhoods_sunderland.gpkg\n",
      "Saved: ../../bikenwgrowth_external/data/north_tyneside\\neighbourhoods_north_tyneside.gpkg\n"
     ]
    }
   ],
   "source": [
    "## Read in from Github\n",
    "github_link = \"https://raw.githubusercontent.com/Froguin99/LTN-Detection/main/data/Tyne%26Wear/\"\n",
    "raw_files = [\n",
    "    \"scored_neighbourhoods_Gateshead.gpkg\",\n",
    "    \"scored_neighbourhoods_Newcastle Upon Tyne.gpkg\",\n",
    "    \"scored_neighbourhoods_South Tyneside.gpkg\",\n",
    "    \"scored_neighbourhoods_Sunderland.gpkg\",\n",
    "    \"scored_neighbourhoods_North Tyneside.gpkg\"] # just Tyne & Wear for now...\n",
    "\n",
    "# Manual map: filename place â†’ folder name. Tried a fuzzy matching (lower down adn commented out) but haven't got it quite right yet...\n",
    "folder_map = {\n",
    "    \"Gateshead\": \"gateshead\",\n",
    "    \"Newcastle Upon Tyne\": \"newcastle\",\n",
    "    \"South Tyneside\": \"south_tyneside\",\n",
    "    \"Sunderland\": \"sunderland\",\n",
    "    \"North Tyneside\": \"north_tyneside\"\n",
    "}\n",
    "\n",
    "columns_to_convert = [\n",
    "    \"rat_run_score\", \"mean_distance_diff_score\",\n",
    "    \"filter_road_density_score\", \"overall_score\", \"cluster_label\"\n",
    "]\n",
    "\n",
    "\n",
    "# save just LTN neighbourhoods based on the \n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "\n",
    "    # Build final filename and download path\n",
    "    new_fname = f\"scored_neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "\n",
    "    # Download\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "\n",
    "    # Load and clean\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    ltns = gdf[gdf[\"overall_score\"] > ltn_plausiablity_score]\n",
    "\n",
    "    # Save to correct folder\n",
    "    output_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    ltns.to_file(output_path, layer=new_fname.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "\n",
    "\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "\n",
    "# save all neighbourhoods, regardless of how much traffic they have within them\n",
    "for fname in raw_files:\n",
    "    place = fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\")\n",
    "    folder = folder_map.get(place)\n",
    "    if not folder:\n",
    "        print(f\"Skipping {place}: no folder mapping.\")\n",
    "        continue\n",
    "    new_fname = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    url = github_link + fname\n",
    "    download_path = os.path.join(PATH[\"data\"], folder, new_fname)\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "    with open(download_path, \"wb\") as f:\n",
    "        f.write(requests.get(url).content)\n",
    "    gdf = gpd.read_file(download_path)\n",
    "    gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    out_name = f\"neighbourhoods_{folder}.gpkg\"\n",
    "    output_path = os.path.join(PATH[\"data\"], folder, out_name)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    gdf.to_file(output_path, layer=out_name.replace(\".gpkg\", \"\"), driver=\"GPKG\", overwrite=True)\n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fuzzy matching attempt\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# columns_to_convert = [\"rat_run_score\", \"mean_distance_diff_score\", \"filter_road_density_score\", \"overall_score\", \"cluster_label\"]\n",
    "\n",
    "\n",
    "# def place_from_filename(fname):\n",
    "#     return fname.replace(\"scored_neighbourhoods_\", \"\").replace(\".gpkg\", \"\").strip()\n",
    "\n",
    "# # Function to fuzzy match the place to the folder names\n",
    "# def get_matching_folder(place_name, folder_names):\n",
    "#     match = process.extractOne(place_name, folder_names)\n",
    "#     return match[0] if match[1] >= 80 else None  # threshold of 80% similarity\n",
    "\n",
    "# # Get available folder names in PATH['data']\n",
    "# available_folders = [folder for folder in os.listdir(PATH[\"data\"]) if os.path.isdir(os.path.join(PATH[\"data\"], folder))]\n",
    "\n",
    "# # Process each file\n",
    "# for fname in raw_files:\n",
    "#     place_name = place_from_filename(fname)\n",
    "#     matching_folder = get_matching_folder(place_name, available_folders)\n",
    "    \n",
    "#     if not matching_folder:\n",
    "#         print(f\"No match found for {place_name}. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Download the file\n",
    "#     url = github_link + fname\n",
    "#     local_tmp = fname  # Save temporarily with original name\n",
    "#     with open(local_tmp, \"wb\") as f:\n",
    "#         f.write(requests.get(url).content)\n",
    "\n",
    "#     # Read and filter\n",
    "#     gdf = gpd.read_file(local_tmp)\n",
    "#     gdf[columns_to_convert] = gdf[columns_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "#     ltns = gdf[gdf[\"overall_score\"] > 50]\n",
    "\n",
    "#     # Define the output path using the matched folder name\n",
    "#     output_path = os.path.join(PATH[\"data\"], matching_folder, fname)\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "#     # Save the file\n",
    "#     ltns.to_file(output_path, driver=\"GPKG\")\n",
    "#     print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "#     if placeinfo[\"nominatimstring\"] != '':\n",
    "#         location = ox.geocoder.geocode_to_gdf(placeinfo[\"nominatimstring\"])\n",
    "#         if location.geometry[0].geom_type == 'MultiPolygon':\n",
    "#             location = location.explode(index_parts=False).reset_index(drop=True)\n",
    "#         location = fill_holes(extract_relevant_polygon(placeid, shapely.geometry.shape(location['geometry'][0])))\n",
    "#         if debug: # Draw location polygons and their holes\n",
    "#             try:\n",
    "#                 color = cm.rainbow(np.linspace(0,1,len(location)))\n",
    "#                 for poly,c in zip(location, color):\n",
    "#                     plt.plot(*poly.exterior.xy, c = c)\n",
    "#                     for intr in poly.interiors:\n",
    "#                         plt.plot(*intr.xy, c = \"red\")\n",
    "#             except:\n",
    "#                 plt.plot(*location.exterior.xy)\n",
    "#             plt.show()\n",
    "#     else:\n",
    "#         # https://gis.stackexchange.com/questions/113799/how-to-read-a-shapefile-in-python\n",
    "#         shp = fiona.open(PATH[\"data\"] + placeid + \"/\" + placeid + \".shp\")\n",
    "#         first = next(iter(shp))\n",
    "#         try:\n",
    "#             location = Polygon(shapely.geometry.shape(first['geometry'])) # If shape file is given as linestring\n",
    "#         except:\n",
    "#             location = shapely.geometry.shape(first['geometry'])\n",
    "\n",
    "#     Gs = {}\n",
    "#     for parameterid, parameterinfo in tqdm(osmnxparameters.items(), desc = \"Networks\", leave = False):\n",
    "#         for i in range(0,10): # retry\n",
    "#             try:\n",
    "#                 Gs[parameterid] = ox.graph_from_polygon(location, \n",
    "#                                        network_type = parameterinfo['network_type'],\n",
    "#                                        custom_filter = (parameterinfo['custom_filter']),\n",
    "#                                        retain_all = parameterinfo['retain_all'],\n",
    "#                                        simplify = False)\n",
    "#             except ValueError:\n",
    "#                 Gs[parameterid] = nx.empty_graph(create_using = nx.MultiDiGraph)\n",
    "#                 print(placeid + \": No OSM data for graph \" + parameterid + \". Created empty graph.\")\n",
    "#                 break\n",
    "#             except ConnectionError or UnboundLocalError:\n",
    "#                 print(\"ConnectionError or UnboundLocalError. Retrying.\")\n",
    "#                 continue\n",
    "#             except:\n",
    "#                 print(\"Other error. Retrying.\")\n",
    "#                 continue\n",
    "#             break\n",
    "#         if parameterinfo['export']: ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid), ox.save_graph_geopackage(Gs[parameterid], filepath = PATH[\"data\"] + placeid + \"/\" + placeid + \"_\" + parameterid + \".gpkg\", directed = False)\n",
    "\n",
    "#     # if we have any LTNs, get the neighbourhood streets and save them to \n",
    "\n",
    "#     # if we have any LTNs, get the neighbourhood streets and save them to \n",
    "#     neighbourhoods = load_neighbourhoods(PATH[\"data\"] + placeid + \"/\")\n",
    "#     if not neighbourhoods:\n",
    "#         print(placeid + \": No LTN dataset found.\")\n",
    "#     else:\n",
    "#         neighbourhoods = prepare_neighbourhoods(neighbourhoods)\n",
    "#         city_neighbourhood_streets = {}\n",
    "\n",
    "#         for city_name, gdf in neighbourhoods.items():\n",
    "#             if debug:\n",
    "#                 print(f\"Processing streets for {city_name}...\")\n",
    "#             nodes, edges, neighbourhood_graphs = get_neighbourhood_street_graph(gdf, debug)  # get streets within neighbourhoods\n",
    "#             neighbourhood_graphs = process_lists(neighbourhood_graphs)\n",
    "#             city_neighbourhood_streets[city_name] = {'nodes': nodes,'edges': edges, 'neighbourhood_graphs': neighbourhood_graphs}\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "#     # Compose special cases biketrack, bikeable, biketrackcarall, ltnstreets\n",
    "#     parameterid = 'biketrack'\n",
    "#     if city_name in city_neighbourhood_streets:\n",
    "#         neighbourhood_graph = city_neighbourhood_streets[city_name]['neighbourhood_graphs']\n",
    "#         Gs[parameterid] = nx.compose_all([\n",
    "#             Gs['bike_cyclewaylefttrack'],\n",
    "#             Gs['bike_cyclewaytrack'],\n",
    "#             Gs['bike_highwaycycleway'],\n",
    "#             Gs['bike_bicycleroad'],\n",
    "#             Gs['bike_cyclewayrighttrack'],\n",
    "#             Gs['bike_designatedpath'],\n",
    "#             Gs['bike_cyclestreet']\n",
    "#             ,neighbourhood_graph\n",
    "#             ])\n",
    "#     ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid)\n",
    "#     ox.save_graph_geopackage(Gs[parameterid], filepath = PATH[\"data\"] + placeid + \"/\" + placeid + \"_\" + parameterid + \".gpkg\", directed = False)\n",
    "\n",
    "     \n",
    "#     parameterid = 'bikeable'\n",
    "#     Gs[parameterid] = nx.compose_all([Gs['biketrack'], Gs['car30'], Gs['bike_livingstreet']]) \n",
    "#     ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid)\n",
    "#     ox.save_graph_geopackage(Gs[parameterid], filepath = PATH[\"data\"] + placeid + \"/\" + placeid + \"_\" + parameterid + \".gpkg\", directed = False)\n",
    "\n",
    "#     parameterid = 'biketrackcarall'\n",
    "#     Gs[parameterid] = nx.compose(Gs['biketrack'], Gs['carall']) # Order is important\n",
    "#     ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid)\n",
    "#     ox.save_graph_geopackage(Gs[parameterid], filepath = PATH[\"data\"] + placeid + \"/\" + placeid + \"_\" + parameterid + \".gpkg\", directed = False)\n",
    "\n",
    "#     #parameterid = 'ltnstreets'\n",
    "#     #Gs[parameterid] = neighbourhoods_G\n",
    "#     #ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid)\n",
    "\n",
    "#     parameterid = 'biketrack_no_ltn'\n",
    "#     Gs[parameterid] = nx.compose_all([\n",
    "#         Gs['bike_cyclewaylefttrack'],\n",
    "#         Gs['bike_cyclewaytrack'],\n",
    "#         Gs['bike_highwaycycleway'],\n",
    "#         Gs['bike_bicycleroad'],\n",
    "#         Gs['bike_cyclewayrighttrack'],\n",
    "#         Gs['bike_designatedpath'],\n",
    "#         Gs['bike_cyclestreet']\n",
    "#         ])\n",
    "#     ox_to_csv(Gs[parameterid], PATH[\"data\"] + placeid + \"/\", placeid, parameterid)\n",
    "#     ox.save_graph_geopackage(Gs[parameterid], filepath = PATH[\"data\"] + placeid + \"/\" + placeid + \"_\" + parameterid + \".gpkg\", directed = False)\n",
    "\n",
    "\n",
    "#     for parameterid in networktypes[:-2]:\n",
    "#         #G_temp = nx.MultiDiGraph(ox.utils_graph.get_digraph(ox.simplify_graph(Gs[parameterid]))) # This doesnt work - cant get rid of multiedges\n",
    "#         ox_to_csv(ox.simplify_graph(Gs[parameterid]), PATH[\"data\"] + placeid + \"/\", placeid, parameterid, \"_simplified\")\n",
    "\n",
    "#     # Handle unhashable list issue with LTN streets (source issue to do with OSM edges having lists as attributes, which shouldn't be the case!!)\n",
    "#     # for u, v, data in neighbourhoods_G.edges(data=True):\n",
    "#     #     for attr, value in data.items():\n",
    "#     #         if isinstance(value, list):\n",
    "#     #             data[attr] = str(value)\n",
    "#     # ox_to_csv(ox.simplify_graph(neighbourhoods_G), PATH[\"data\"] + placeid + \"/\", placeid, \"ltnstreets\", \"_simplified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
